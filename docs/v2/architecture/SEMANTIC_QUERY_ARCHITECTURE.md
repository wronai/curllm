# Semantic Query Architecture

## Problem z Obecnym Systemem

### Monolityczne Heuristics (stare podejÅ›cie):
```python
result = await product_heuristics(instruction, page, logger)
# Zwraca: {"products": []} lub {"products": [...]}
```

**Problemy:**
1. âŒ **Black box** - nie wiesz DLACZEGO nie dziaÅ‚a
2. âŒ **Brak debugowania** - all-or-nothing
3. âŒ **Brak feedback** - LLM nie moÅ¼e dostosowaÄ‡ strategii
4. âŒ **Nieelastyczne** - jeden sposÃ³b dla wszystkich stron
5. âŒ **Niewydajne** - skanuje caÅ‚y DOM za kaÅ¼dym razem

### Log z monolitycznego systemu:
```
ğŸ”§ Step 1/3: Scroll to load items
   âœ… Success

ğŸ”§ Step 2/3: Extract products  
   Tool: products.heuristics
   âŒ count: 0
   
Dlaczego 0? Co poszÅ‚o nie tak?
- Nie znalazÅ‚ kontenerÃ³w?
- ZnalazÅ‚ kontenery ale nie price?
- Price byÅ‚ ale URL byÅ‚ zÅ‚y?
- ???
```

## âœ¨ Nowe RozwiÄ…zanie: Semantic Query Engine

### TrÃ³jwarstwowa Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 3: Natural Language (User Input)              â”‚
â”‚ "Find products under 150zÅ‚ with ratings > 4"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ LLM parses
                     v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: Structured Query (Semantic)                â”‚
â”‚ {                                                    â”‚
â”‚   "intent": "extract_products",                     â”‚
â”‚   "entity_type": "product",                         â”‚
â”‚   "fields": [                                        â”‚
â”‚     {"name": "name", "type": "text"},               â”‚
â”‚     {"name": "price", "type": "number"},            â”‚
â”‚     {"name": "rating", "type": "number"}            â”‚
â”‚   ],                                                 â”‚
â”‚   "filters": [                                       â”‚
â”‚     {"field": "price", "op": "lte", "value": 150},  â”‚
â”‚     {"field": "rating", "op": "gt", "value": 4}     â”‚
â”‚   ]                                                  â”‚
â”‚ }                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Breaks down into
                     v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: Atomic Functions (Composable)              â”‚
â”‚                                                      â”‚
â”‚ Step 1: find_containers("product", min=1)           â”‚
â”‚   â†’ Found 15 containers with .product-box           â”‚
â”‚                                                      â”‚
â”‚ Step 2: extract_field(container[0], "name")         â”‚
â”‚   â†’ "Odkurzacz ABC XYZ"                             â”‚
â”‚                                                      â”‚
â”‚ Step 3: extract_field(container[0], "price")        â”‚
â”‚   â†’ 149.99                                           â”‚
â”‚                                                      â”‚
â”‚ Step 4: extract_field(container[0], "rating")       â”‚
â”‚   â†’ 4.5                                              â”‚
â”‚                                                      â”‚
â”‚ Step 5: filter(entities, price <= 150)              â”‚
â”‚   â†’ 12 entities pass                                 â”‚
â”‚                                                      â”‚
â”‚ Step 6: validate(entities, required_fields)         â”‚
â”‚   â†’ 10 entities valid                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrzykÅ‚ad UÅ¼ycia

### Kod:
```python
from curllm_core.semantic_query import semantic_extract

result = await semantic_extract(
    instruction="Find products under 150zÅ‚ with ratings",
    page=page,
    llm=llm,
    run_logger=logger
)

print(result)
```

### Output:
```json
{
  "entities": [
    {
      "name": "Odkurzacz ABC XYZ",
      "price": 149.99,
      "url": "https://ceneo.pl/12345",
      "rating": 4.5
    },
    {
      "name": "Mop parowy DEF",
      "price": 139.00,
      "url": "https://ceneo.pl/67890",
      "rating": 4.8
    }
  ],
  "count": 10,
  "quality": {
    "completeness": 0.95,
    "containers_found": 15,
    "extraction_rate": 0.67
  }
}
```

### Log (peÅ‚na transparentnoÅ›Ä‡):
```
ğŸ” Parsed Semantic Query:
{
  "intent": "extract_products",
  "entity_type": "product",
  "fields": [
    {"name": "name", "type": "text", "required": true},
    {"name": "price", "type": "number", "required": true},
    {"name": "url", "type": "url", "required": true},
    {"name": "rating", "type": "number", "required": false}
  ],
  "filters": [
    {"field": "price", "operator": "lte", "value": 150}
  ]
}

âš™ï¸ Executing Query with Atomic Functions
   Found 15 potential containers
   
   â€¢ find_containers: Looking for product containers...
   â€¢ find_containers: Found 15 with .product-box
   
   Container 0:
      â€¢ extract_field(name): "Odkurzacz ABC XYZ"
      â€¢ extract_field(price): 149.99
      â€¢ extract_field(url): "https://ceneo.pl/12345"
      â€¢ extract_field(rating): 4.5
      âœ… Passes filters
   
   Container 1:
      â€¢ extract_field(name): "Mop parowy DEF"
      â€¢ extract_field(price): 139.00
      â€¢ extract_field(url): "https://ceneo.pl/67890"
      â€¢ extract_field(rating): 4.8
      âœ… Passes filters
   
   Container 2:
      â€¢ extract_field(name): "Produkt XYZ"
      â€¢ extract_field(price): 189.99
      â€¢ extract_field(url): "https://ceneo.pl/11111"
      âŒ Filtered out (price > 150)
   
   ...
   
   Extracted 12 entities after filtering
   â€¢ validate_entities: Validated 10/12 entities
   
âœ… Success: 10 products
   Quality: 95% complete, 67% extraction rate
```

## KorzyÅ›ci

### 1. **PeÅ‚na ObserwowalnoÅ›Ä‡**
Widzisz dokÅ‚adnie:
- Ile kontenerÃ³w znaleziono
- Jakie wartoÅ›ci wyciÄ…gniÄ™to z kaÅ¼dego
- KtÃ³re pola siÄ™ nie powiodÅ‚y
- Dlaczego entity zostaÅ‚o odrzucone

### 2. **Granularne Debugowanie**
```
Problem: products_count = 0

Stary system:
- ??? (black box)

Nowy system:
Log pokazuje:
   â€¢ find_containers: Found 15 with .product-box
   â€¢ extract_field(name): âœ… "Product..."
   â€¢ extract_field(price): âŒ None
   â†’ Problem: nie potrafi wyciÄ…gnÄ…Ä‡ price!
   â†’ RozwiÄ…zanie: dodaj pattern dla tego formatu ceny
```

### 3. **Adaptive Extraction**
LLM moÅ¼e:
- PrÃ³bowaÄ‡ rÃ³Å¼ne selektory
- DostosowywaÄ‡ strategiÄ™ na podstawie feedback
- IterowaÄ‡ jeÅ›li pierwsza prÃ³ba nie dziaÅ‚a

```python
# Iteracja 1: PrÃ³ba z .product-box
containers = await executor.find_containers("product")
if len(containers) == 0:
    # Iteracja 2: PrÃ³ba heurystyczna
    containers = await executor._find_containers_heuristic("product")
```

### 4. **Composable & Reusable**
```python
# MoÅ¼na Å‚Ä…czyÄ‡ funkcje atomowe w rÃ³Å¼ne sposoby
# PrzykÅ‚ad 1: Produkty z Ceneo
containers = await find_containers("product")
for c in containers:
    name = await extract_field(c, FieldSpec("name", "text"))
    price = await extract_field(c, FieldSpec("price", "number"))

# PrzykÅ‚ad 2: ArtykuÅ‚y z Hacker News
containers = await find_containers("article")
for c in containers:
    title = await extract_field(c, FieldSpec("title", "text"))
    url = await extract_field(c, FieldSpec("url", "url"))
```

### 5. **Quality Metrics**
```json
{
  "quality": {
    "completeness": 0.95,      // 95% pÃ³l wypeÅ‚nionych
    "containers_found": 15,    // Znaleziono 15 kontenerÃ³w
    "extraction_rate": 0.67    // 67% kontenerÃ³w â†’ valid entities
  }
}
```

Widzisz **jakoÅ›Ä‡** ekstrakcji - nie tylko count!

## PorÃ³wnanie

| Feature | Monolithic Heuristics | Semantic Query Engine |
|---------|----------------------|----------------------|
| **Debugowanie** | âŒ Black box | âœ… Full trace |
| **Feedback dla LLM** | âŒ Tylko count | âœ… SzczegÃ³Å‚owe metryki |
| **ElastycznoÅ›Ä‡** | âŒ One-size-fits-all | âœ… Adaptive strategy |
| **Composability** | âŒ Monolityczne | âœ… Atomic functions |
| **Quality metrics** | âŒ Tylko count | âœ… Completeness, rate, etc. |
| **Iteracja** | âŒ All-or-nothing | âœ… MoÅ¼e prÃ³bowaÄ‡ alternatyw |
| **Testowanie** | âš ï¸ Trudne | âœ… KaÅ¼da funkcja testowalna |

## Integracja z Obecnym Systemem

### Dodaj jako Layer przed Heuristics:

```python
# task_runner.py

# 1. PrÃ³ba: Semantic Query Engine (najlepsze)
result = await semantic_extract(instruction, page, llm, logger)
if result and result["count"] > 0:
    return result

# 2. PrÃ³ba: Tool Orchestrator (dobre)
result = await orchestrate_with_tools(instruction, page, llm, logger)
if result and result.get("products"):
    return result

# 3. Fallback: Monolithic Heuristics (stare)
result = await product_heuristics(instruction, page, logger)
```

### Lub jako Flag:
```bash
CURLLM_USE_SEMANTIC_QUERY=true curllm --stealth "..." -d "..."
```

## Roadmap

### Phase 1: Atomic Functions (DONE âœ…)
- `find_containers()` - identyfikacja kontenerÃ³w
- `extract_field()` - ekstrakcja pojedynczego pola
- `validate_entities()` - walidacja wynikÃ³w

### Phase 2: Semantic Query Parser (DONE âœ…)
- Natural language â†’ Structured query
- LLM parsuje intent, entity_type, fields, filters

### Phase 3: Quality Metrics (DONE âœ…)
- Completeness rate
- Extraction rate
- Container detection stats

### Phase 4: Adaptive Strategy (TODO)
- LLM moÅ¼e zmieniaÄ‡ strategiÄ™ na podstawie feedback
- Iteracyjne ulepszanie selektorÃ³w
- Auto-learning patterns

### Phase 5: Multi-Strategy Execution (TODO)
- PrÃ³buj DOM heuristic + Vision + BQL rÃ³wnolegle
- Wybierz najlepszy wynik
- Ensemble voting

### Phase 6: Caching & Learning (TODO)
- Cache patterns dla popularnych stron
- Learn selectors from successful extractions
- Build site-specific knowledge base

## PrzykÅ‚ady

### E-commerce (Ceneo.pl):
```python
result = await semantic_extract(
    "Find products under 150zÅ‚",
    page, llm, logger
)
# â†’ Full trace, quality metrics, 10 products
```

### News (Hacker News):
```python
result = await semantic_extract(
    "Extract article titles and URLs",
    page, llm, logger
)
# â†’ Full trace, quality metrics, 30 articles
```

### Custom entities:
```python
result = await semantic_extract(
    "Find comments with rating > 4 stars",
    page, llm, logger
)
# â†’ Full trace, quality metrics, 15 comments
```

## Migracja

### Stary kod:
```python
# Monolityczny
result = await product_heuristics(instruction, page, logger)
if not result or result.get("products") == []:
    # ??? Co teraz?
    pass
```

### Nowy kod:
```python
# Semantic + Atomic
result = await semantic_extract(instruction, page, llm, logger)

if result["count"] == 0:
    # Widzisz DLACZEGO:
    if result["quality"]["containers_found"] == 0:
        # Problem: nie znaleziono kontenerÃ³w
        # â†’ PrÃ³buj innej strategii lub innej strony
        pass
    elif result["quality"]["extraction_rate"] < 0.3:
        # Problem: kontenery OK, ale ekstrakcja pÃ³l sÅ‚aba
        # â†’ Dodaj custom patterns dla tej strony
        pass
```

## NastÄ™pne Kroki

1. **Przetestuj na Ceneo:**
```bash
CURLLM_USE_SEMANTIC_QUERY=true curllm --stealth "https://ceneo.pl/..." -d "Find products under 150zÅ‚"
```

2. **PorÃ³wnaj logi:**
   - Stary: `products_count: 0` (brak info)
   - Nowy: Full execution trace + quality metrics

3. **Iteruj na podstawie feedback:**
   - JeÅ›li `containers_found: 0` â†’ problem z selektorami
   - JeÅ›li `extraction_rate: 0.1` â†’ problem z field extraction
   - JeÅ›li `completeness: 0.5` â†’ brakuje niektÃ³rych pÃ³l

4. **Rozszerz:**
   - Dodaj wiÄ™cej atomic functions
   - Dodaj adaptive retry logic
   - Dodaj site-specific optimizations
