# Running Docker Tests - Quick Guide

## ğŸš€ Quick Start

### Option 1: Run All Tests (Recommended)

```bash
make test-docker
```

This will:
1. Build Docker images
2. Start test web server with 10 test pages
3. Start mock Ollama server
4. Run all integration tests
5. Generate HTML test report

### Option 2: Step by Step

```bash
# 1. Build test environment
make test-docker-build

# 2. Run tests
make test-docker-run

# 3. View results
open test_results/report.html
```

### Option 3: Manual Docker Compose

```bash
# Start all services
docker-compose -f docker-compose.test.yml up

# Run tests only
docker-compose -f docker-compose.test.yml run curllm-test

# Stop all services
docker-compose -f docker-compose.test.yml down
```

---

## ğŸ“„ Test Pages

### View Test Pages Locally

```bash
make test-pages
```

Then visit: `http://localhost:8080/01_simple_form.html`

### Available Test Pages (10)

1. **01_simple_form.html** - Basic contact form
2. **02_product_list.html** - Product catalog
3. **03_login_form.html** - Login page
4. **04_registration.html** - Multi-field registration
5. **05_search_results.html** - Search results page
6. **06_data_table.html** - Data table extraction
7. **07_newsletter.html** - Newsletter subscription
8. **08_multi_step_form.html** - Multi-step form wizard
9. **09_ecommerce_cart.html** - Shopping cart
10. **10_feedback_form.html** - Feedback form with rating

---

## ğŸ§ª Integration Tests (10)

### Test Suite

All tests use **LLM-DSL Bridge** to communicate with Streamware components via JSON/YAML:

1. **test_01_simple_form.py** - Form filling via LLM-DSL
2. **test_02_product_extraction.py** - Data extraction
3. **test_03_to_10.py** - Comprehensive test suite:
   - Login automation
   - Registration forms
   - Search results
   - Table extraction
   - Newsletter subscription
   - Multi-step forms
   - Shopping cart
   - Feedback forms

### LLM-DSL Communication Example

```python
# LLM sends JSON command
command = {
    "action": "analyze_form",
    "components": [
        {"type": "dom-snapshot", "params": {"include_values": True}},
        {"type": "field-mapper", "params": {"strategy": "fuzzy"}}
    ]
}

# Bridge executes Streamware components
result = bridge.execute_llm_command(command)
```

---

## ğŸ“Š Test Results

### HTML Report

After running tests, view the report:

```bash
open test_results/report.html
# or
firefox test_results/report.html
```

### Console Output

Tests provide detailed output including:
- Component execution trace
- LLM-DSL commands sent
- Validation results
- Screenshots (in `./screenshots/`)

---

## ğŸ”§ Architecture

### Docker Services

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ test-webserver   â”‚  Nginx serving 10 test HTML pages
â”‚ (port 8080)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ mock-ollama      â”‚  Mock Ollama server for LLM responses
â”‚ (port 11434)     â”‚  Returns pre-defined JSON/YAML commands
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ curllm-test      â”‚  Test runner with Playwright
â”‚                  â”‚  Executes 10 integration tests
â”‚                  â”‚  Uses LLM-DSL Bridge
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LLM-DSL Flow

```
Test â†’ LLM Command (JSON/YAML) â†’ LLMDSLBridge â†’ Streamware Components â†’ Browser Actions
```

---

## ğŸ› Debugging

### View Logs

```bash
# All logs
docker-compose -f docker-compose.test.yml logs

# Specific service
docker-compose -f docker-compose.test.yml logs curllm-test
docker-compose -f docker-compose.test.yml logs mock-ollama
```

### Run Single Test

```bash
docker-compose -f docker-compose.test.yml run curllm-test \
    pytest tests/integration/test_01_simple_form.py -v
```

### Interactive Shell

```bash
docker-compose -f docker-compose.test.yml run curllm-test bash
```

---

## ğŸ“ Environment Variables

### Test Configuration

- `CURLLM_TEST_BASE_URL` - Test pages URL (default: `http://test-webserver`)
- `CURLLM_OLLAMA_HOST` - Mock Ollama URL (default: `http://mock-ollama:11434`)
- `CURLLM_HEADLESS` - Run headless (default: `true`)
- `CURLLM_TEST_MODE` - Enable test mode (default: `true`)

### Customize

```bash
# Run tests with custom Ollama host
CURLLM_OLLAMA_HOST=http://localhost:11434 make test-docker
```

---

## ğŸ¯ What Gets Tested

### Form Filling
- âœ… Simple contact forms
- âœ… Multi-field registration
- âœ… Login forms
- âœ… Multi-step wizards
- âœ… Checkboxes and radio buttons
- âœ… Dropdown selects

### Data Extraction
- âœ… Product listings
- âœ… Search results
- âœ… Data tables
- âœ… Shopping carts

### LLM-DSL Communication
- âœ… JSON command parsing
- âœ… YAML command parsing
- âœ… Component chaining
- âœ… Action planning
- âœ… State validation
- âœ… Field mapping

### Components Tested
- âœ… dom-snapshot (with value fix)
- âœ… dom-analyze
- âœ… field-mapper
- âœ… action-plan
- âœ… action-validate
- âœ… dom-validate
- âœ… decision-tree

---

## ğŸ”„ Cleanup

```bash
# Stop and remove containers
docker-compose -f docker-compose.test.yml down

# Remove volumes
docker-compose -f docker-compose.test.yml down -v

# Clean test results
rm -rf test_results/* screenshots/*
```

---

## ğŸ“š Additional Resources

- **Main Documentation**: `STREAMWARE_ARCHITECTURE.md`
- **DSL Guide**: `REFACTORING_DSL_COMPLETE.md`
- **Bug Analysis**: `DOM_FIX_ANALYSIS.md`
- **YAML Flows**: `YAML_FLOWS.md`

---

## âœ… Expected Results

After running `make test-docker`, you should see:

```
âœ“ 10 test pages served on http://test-webserver
âœ“ Mock Ollama responding on http://mock-ollama:11434
âœ“ All 10+ integration tests passing
âœ“ HTML report generated in test_results/
âœ“ Screenshots saved in screenshots/
```

---

**Ready to test!** Run `make test-docker` to start. ğŸš€
